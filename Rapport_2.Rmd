---
output: pdf_document
header-includes:
- \usepackage[french]{babel}
- \usepackage{float}
- \usepackage{titling}
- \DeclareUnicodeCharacter{2212}{-}
---
\begin{titlingpage}
  \rightline{Équipe 2}
  \centering
  \Large
  Travail fait par \\
  \vspace{1cm}
  \text{Matis Brassard-Verrier (111 182 740) }\\
  \text{Alyson Marquis (111 183 605)}\\
  \text{Alexis Picard (111 182 200)}\\
  \text{Samuel Provencher (111 181 794)}\\
  \vfill
  \Large
  Apprentissage statistique en actuariat \\
  \vspace{0.5cm}
  \text{ACT-3114}
  \vfill
  \Large
  Rapport 2\\
  \vfill
  \Large
  Présenté à\\
  \vspace{0.5cm}
  \text{Marie-Pier Côté}
  \vfill
  \Large
  École d'actuariat\\
  \text{Université Laval}\\
  \text{22 avril 2020}
\end{titlingpage}

\pagenumbering{gobble}

\tableofcontents

\newpage
\pagenumbering{arabic}




\section{Introduction}

Dans le cadre du travail, nous allons tenter de modéliser le prix de vente des maisons dans la région de Seattle (King County, USA) en utilisant de nombreuses caractéristiques ayant une incidence sur la valeur d'une maison. La variable réponse à prédire, soit le prix de vente d'une maison, est une valeur positive évaluée en dollars américains. La modélisation de cette variable pourrait être utile pour différentes raisons dans un contexte actuariel. Comme la somme assurée d'une maison a un lien très fortement proportionnel à son prix de vente, une compagnie d'assurance pourrait être intéressée de modéliser le prix de vente de maisons dans des nouveaux développements immobiliers afin de tenter de prédire les futures soumissions d'assurance habitation et d'offrir des offres personnalisées aux acheteurs de ces nouvelles maisons. Dans un autre contexte, au niveau de la gestion des risques, certains assureurs ont un portefeuille de prêts hypothécaires ou utilisent des produits dérivés sur prêts hypothécaires pour se couvrir du risque (*hedging*). Ainsi, il pourrait être intéressant d'avoir une estimation des montants de prêts hypothécaires dans une région donnée en se basant sur le prix de vente des maisons afin de mieux gérer le risque de la compagnie. La pertinence de trouver cette variable qu'est le prix de vente des maisons devient alors fort intéressante. 

Le jeu de données utilisé sera le suivant : [kc_house_sales (House sales in King County, USA)](https://www.kaggle.com/harlfoxem/housesalesprediction). Dans les prochaines sections, sept modèles seront étudiés, dont deux qui le seront plus en profondeur. Pour ce faire, 80 % des données seront utilisées pour effectuer l'entraînement des modèles et 20 % seront réservées pour tester ainsi que comparer les modèles entre eux.



\section{Modèle de base}

```{r ModBas, echo=FALSE}

source("1-ModeleBase.R")

```

Un bon modèle de base a été choisi en utilisant une technique étudiée dans le cours ACT-2003 Modèles linéaires en actuariat, soit la régression linéaire multiple. Ce type de modèle a été choisi en raison de sa simplicité et parce qu'il s'adapte bien au jeu de données. En effet, la variable réponse *price* est monétaire et possède une distribution asymétrique. Il a été vu, qu'en présence de ce type de variable réponse, une régression linéaire multiple en appliquant une transformation logarithmique sur la variable réponse était appropriée. Tel que mentionné dans la première partie de ce travail, la transformation logarithmique permet de s'approcher de la distribution d'une loi normale, ce qui rend la variable réponse plus facile à modéliser. Pour construire le modèle, seulement l'échantillon d'entrainement a été utilisé. De plus, le modèle utilise toutes les $17$ variables explicatives. Cependant, aucune interaction entre les variables explicatives n'a été considérée afin de garder le modèle simple et facilement intrprétable. Certaines variables catégorielles à plusieurs niveaux, dont l'importance des interactions étaient négligeables augmentaient le temps de calculs et rendaient le modèle plus difficilement interprétable. Ainsi, dans l'idée d'avoir un modèle de base simple, il a été décidé de ne pas considérer les interactions dans ce modèle. En outre, une sélection de variable formelle n'a pas été effectuée contrairement à ce qui est habituellement fait lorsqu'on veut raffiner un modèle linéaire multiple.

\newpage
\section{Ajustement des modèles}



\subsection{Modèle linéaire généralisé avec une régularisation Lasso}
```{r echo=FALSE, eval=T, message=FALSE}
source("2-Lasso.R")
```
Dans le cadre du travail, il a été choisi d'effectuer un modèle linéaire généralisé avec une régularisation de type Lasso. Notre choix s'est arrêté sur ce type de régularisation, puisque la régularisation Lasso permet d'effectuer la sélection de variables. Pour se faire, il suffit de minimiser l'équation de score suivante :
$$
S^{Lasso} = \sum_{i=1}^{p}(Y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij})^2 + \lambda \sum_{j=1}^{p} \lvert{\beta_j} \rvert,
$$
où $p$ est le nombre de paramètres du modèle et $\lambda$ est le paramètre de régularisation. La minimisation de cette équation mènera à des coefficients $\beta$ exactement égal à zéro, sélectionnant ainsi les variables du modèle.

Afin de modéliser le prix de vente des maisons à King County, le modèle linéaire généralisé avec une régularisation Lasso  a été construit à l'aide de l'échantillon d'entraînement. Le paramètre de régularisation a été choisi à l'aide d'une validation croisée à six plis. Sa valeur est de $\lambda=$`r meilleur.lam.lasso`. Le modèle retenu est composé de sept variables explicatives. Le modèle est aussi constitué de 22 termes d'interaction.  

\subsection{Modèle des k plus proches voisins}



\subsection{Arbre de décision}


\subsection{Ensemble d'arbres de décisions aggrégées par \textit{bagging}}

\subsection{Forêt aléatoire}


\subsection{Modèle de \textit{gradient boosting}}


\newpage
\section{Comparaison des modèles}

\newpage
\section{Interprétation des meilleurs modèles}

\newpage
\section{Conclusion}

\newpage
\section{Bibliographie}

1. Kaggle, harlfoxen (2017). House sales in King County, USA. Récupéré le 27 février 2020 de https://www.kaggle.com/harlfoxem/housesalesprediction.
\newline
2. Max Kuhn (2020). caret: Classification and Regression Training. R package version 6.0-85.
  https://CRAN.R-project.org/package=caret
\newline
3. Terry Therneau and Beth Atkinson (2019). rpart: Recursive Partitioning and Regression Trees. R package
  version 4.1-15. https://CRAN.R-project.org/package=rpart
\newline
4. Stephen Milborrow (2019). rpart.plot: Plot 'rpart' Models: An Enhanced Version of 'plot.rpart'. R
  package version 3.0.8. https://CRAN.R-project.org/package=rpart.plot
\newline
5. A. Liaw and M. Wiener (2002). Classification and Regression by randomForest. R News 2(3), 18--22.
\newline
6. Brandon Greenwell, Bradley Boehmke, Jay Cunningham and GBM Developers (2019). gbm: Generalized Boosted
  Regression Models. R package version 2.1.5. https://CRAN.R-project.org/package=gbm
  \newline
7. Jerome Friedman, Trevor Hastie, Robert Tibshirani (2010). Regularization Paths for Generalized Linear
  Models via Coordinate Descent. Journal of Statistical Software, 33(1), 1-22. URL
  http://www.jstatsoft.org/v33/i01/.
  


